{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing relevant libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from numpy import expand_dims, zeros, ones\n",
    "from numpy.random import randn, randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LMHuDms3Yi6"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data from: https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/\n",
    "# code from: https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "\n",
    "data = pd.read_csv('C:/Users/97254/Documents/Generative_Models/project/datasets/fer2013.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PublicTest      3589\n",
       "PrivateTest     3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "img_width = 48\n",
    "img_height = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pixels']\n",
    "y = data['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in X:\n",
    "    X_train.append([int(j) for j in i.split()])\n",
    "\n",
    "X_train = np.array(X_train)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n",
    "X_train = X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 48, 48, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(48,48,1)):\n",
    "    model = Sequential()\n",
    "    # downsample\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    # foundation for 12x12 image\n",
    "    n_nodes = 128 * 12 * 12\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((12, 12, 128)))\n",
    "    # upsample to 24x24\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 48x48\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # generate\n",
    "    model.add(Conv2D(1, (12, 12), activation='tanh', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# enumerate batches over the training set\n",
    "\t\tfor j in range(bat_per_epo):\n",
    "\t\t\t# get randomly selected 'real' samples\n",
    "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t\t# generate 'fake' examples\n",
    "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t\t# prepare points in latent space as input for the generator\n",
    "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t\t# create inverted labels for the fake samples\n",
    "\t\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t\t# update the generator via the discriminator's error\n",
    "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t\t# summarize loss on this batch\n",
    "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\t# save the generator model\n",
    "\tg_model.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97254\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\97254\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 1/280, d1=0.734, d2=0.695 g=0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97254\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 2/280, d1=0.619, d2=0.705 g=0.680\n",
      ">1, 3/280, d1=0.531, d2=0.730 g=0.655\n",
      ">1, 4/280, d1=0.465, d2=0.774 g=0.617\n",
      ">1, 5/280, d1=0.412, d2=0.841 g=0.570\n",
      ">1, 6/280, d1=0.391, d2=0.934 g=0.517\n",
      ">1, 7/280, d1=0.390, d2=1.014 g=0.473\n",
      ">1, 8/280, d1=0.382, d2=1.090 g=0.445\n",
      ">1, 9/280, d1=0.398, d2=1.136 g=0.428\n",
      ">1, 10/280, d1=0.441, d2=1.112 g=0.442\n",
      ">1, 11/280, d1=0.480, d2=1.077 g=0.461\n",
      ">1, 12/280, d1=0.503, d2=1.020 g=0.496\n",
      ">1, 13/280, d1=0.538, d2=0.956 g=0.526\n",
      ">1, 14/280, d1=0.577, d2=0.896 g=0.571\n",
      ">1, 15/280, d1=0.608, d2=0.847 g=0.614\n",
      ">1, 16/280, d1=0.633, d2=0.785 g=0.657\n",
      ">1, 17/280, d1=0.654, d2=0.735 g=0.689\n",
      ">1, 18/280, d1=0.674, d2=0.711 g=0.733\n",
      ">1, 19/280, d1=0.692, d2=0.665 g=0.763\n",
      ">1, 20/280, d1=0.710, d2=0.633 g=0.795\n",
      ">1, 21/280, d1=0.724, d2=0.603 g=0.834\n",
      ">1, 22/280, d1=0.745, d2=0.576 g=0.868\n",
      ">1, 23/280, d1=0.756, d2=0.553 g=0.885\n",
      ">1, 24/280, d1=0.763, d2=0.543 g=0.916\n",
      ">1, 25/280, d1=0.778, d2=0.523 g=0.936\n",
      ">1, 26/280, d1=0.805, d2=0.511 g=0.949\n",
      ">1, 27/280, d1=0.798, d2=0.492 g=0.979\n",
      ">1, 28/280, d1=0.816, d2=0.491 g=0.979\n",
      ">1, 29/280, d1=0.810, d2=0.475 g=1.000\n",
      ">1, 30/280, d1=0.818, d2=0.473 g=1.019\n",
      ">1, 31/280, d1=0.830, d2=0.471 g=1.020\n",
      ">1, 32/280, d1=0.832, d2=0.463 g=1.034\n",
      ">1, 33/280, d1=0.829, d2=0.451 g=1.032\n",
      ">1, 34/280, d1=0.840, d2=0.453 g=1.037\n",
      ">1, 35/280, d1=0.835, d2=0.452 g=1.051\n",
      ">1, 36/280, d1=0.844, d2=0.454 g=1.036\n",
      ">1, 37/280, d1=0.835, d2=0.448 g=1.039\n",
      ">1, 38/280, d1=0.842, d2=0.449 g=1.029\n",
      ">1, 39/280, d1=0.848, d2=0.466 g=1.018\n",
      ">1, 40/280, d1=0.849, d2=0.466 g=1.007\n",
      ">1, 41/280, d1=0.848, d2=0.478 g=0.984\n",
      ">1, 42/280, d1=0.859, d2=0.496 g=0.951\n",
      ">1, 43/280, d1=0.853, d2=0.530 g=0.907\n",
      ">1, 44/280, d1=0.841, d2=0.550 g=0.861\n",
      ">1, 45/280, d1=0.844, d2=0.591 g=0.818\n",
      ">1, 46/280, d1=0.824, d2=0.618 g=0.779\n",
      ">1, 47/280, d1=0.821, d2=0.642 g=0.756\n",
      ">1, 48/280, d1=0.814, d2=0.655 g=0.735\n",
      ">1, 49/280, d1=0.817, d2=0.667 g=0.725\n",
      ">1, 50/280, d1=0.795, d2=0.670 g=0.719\n",
      ">1, 51/280, d1=0.780, d2=0.675 g=0.718\n",
      ">1, 52/280, d1=0.754, d2=0.669 g=0.721\n",
      ">1, 53/280, d1=0.752, d2=0.667 g=0.726\n",
      ">1, 54/280, d1=0.731, d2=0.659 g=0.731\n",
      ">1, 55/280, d1=0.716, d2=0.658 g=0.738\n",
      ">1, 56/280, d1=0.698, d2=0.652 g=0.747\n",
      ">1, 57/280, d1=0.682, d2=0.648 g=0.748\n",
      ">1, 58/280, d1=0.675, d2=0.644 g=0.751\n",
      ">1, 59/280, d1=0.649, d2=0.642 g=0.752\n",
      ">1, 60/280, d1=0.639, d2=0.644 g=0.749\n",
      ">1, 61/280, d1=0.617, d2=0.646 g=0.743\n",
      ">1, 62/280, d1=0.610, d2=0.655 g=0.736\n",
      ">1, 63/280, d1=0.584, d2=0.665 g=0.727\n",
      ">1, 64/280, d1=0.572, d2=0.677 g=0.711\n",
      ">1, 65/280, d1=0.552, d2=0.690 g=0.700\n",
      ">1, 66/280, d1=0.544, d2=0.703 g=0.684\n",
      ">1, 67/280, d1=0.541, d2=0.718 g=0.669\n",
      ">1, 68/280, d1=0.525, d2=0.737 g=0.653\n",
      ">1, 69/280, d1=0.529, d2=0.755 g=0.636\n",
      ">1, 70/280, d1=0.503, d2=0.774 g=0.624\n",
      ">1, 71/280, d1=0.494, d2=0.791 g=0.608\n",
      ">1, 72/280, d1=0.496, d2=0.804 g=0.595\n",
      ">1, 73/280, d1=0.498, d2=0.826 g=0.580\n",
      ">1, 74/280, d1=0.484, d2=0.841 g=0.567\n",
      ">1, 75/280, d1=0.487, d2=0.853 g=0.555\n",
      ">1, 76/280, d1=0.478, d2=0.877 g=0.547\n",
      ">1, 77/280, d1=0.492, d2=0.888 g=0.539\n",
      ">1, 78/280, d1=0.498, d2=0.899 g=0.532\n",
      ">1, 79/280, d1=0.489, d2=0.911 g=0.528\n",
      ">1, 80/280, d1=0.506, d2=0.911 g=0.527\n",
      ">1, 81/280, d1=0.516, d2=0.914 g=0.527\n",
      ">1, 82/280, d1=0.511, d2=0.908 g=0.529\n",
      ">1, 83/280, d1=0.518, d2=0.904 g=0.537\n",
      ">1, 84/280, d1=0.537, d2=0.898 g=0.537\n",
      ">1, 85/280, d1=0.552, d2=0.890 g=0.548\n",
      ">1, 86/280, d1=0.545, d2=0.873 g=0.557\n",
      ">1, 87/280, d1=0.566, d2=0.855 g=0.566\n",
      ">1, 88/280, d1=0.568, d2=0.851 g=0.574\n",
      ">1, 89/280, d1=0.576, d2=0.839 g=0.582\n",
      ">1, 90/280, d1=0.589, d2=0.815 g=0.601\n",
      ">1, 91/280, d1=0.597, d2=0.805 g=0.612\n",
      ">1, 92/280, d1=0.601, d2=0.792 g=0.622\n",
      ">1, 93/280, d1=0.613, d2=0.783 g=0.627\n",
      ">1, 94/280, d1=0.622, d2=0.761 g=0.654\n",
      ">1, 95/280, d1=0.631, d2=0.740 g=0.663\n",
      ">1, 96/280, d1=0.639, d2=0.744 g=0.663\n",
      ">1, 97/280, d1=0.643, d2=0.736 g=0.679\n",
      ">1, 98/280, d1=0.652, d2=0.714 g=0.689\n",
      ">1, 99/280, d1=0.654, d2=0.704 g=0.699\n",
      ">1, 100/280, d1=0.661, d2=0.691 g=0.708\n",
      ">1, 101/280, d1=0.659, d2=0.685 g=0.717\n",
      ">1, 102/280, d1=0.666, d2=0.669 g=0.728\n",
      ">1, 103/280, d1=0.677, d2=0.656 g=0.739\n",
      ">1, 104/280, d1=0.675, d2=0.649 g=0.743\n",
      ">1, 105/280, d1=0.683, d2=0.644 g=0.748\n",
      ">1, 106/280, d1=0.679, d2=0.639 g=0.763\n",
      ">1, 107/280, d1=0.685, d2=0.636 g=0.767\n",
      ">1, 108/280, d1=0.682, d2=0.632 g=0.770\n",
      ">1, 109/280, d1=0.683, d2=0.631 g=0.768\n",
      ">1, 110/280, d1=0.691, d2=0.623 g=0.782\n",
      ">1, 111/280, d1=0.683, d2=0.622 g=0.785\n",
      ">1, 112/280, d1=0.685, d2=0.617 g=0.790\n",
      ">1, 113/280, d1=0.694, d2=0.610 g=0.790\n",
      ">1, 114/280, d1=0.687, d2=0.614 g=0.793\n",
      ">1, 115/280, d1=0.677, d2=0.608 g=0.793\n",
      ">1, 116/280, d1=0.688, d2=0.615 g=0.790\n",
      ">1, 117/280, d1=0.685, d2=0.613 g=0.798\n",
      ">1, 118/280, d1=0.668, d2=0.615 g=0.796\n",
      ">1, 119/280, d1=0.678, d2=0.618 g=0.785\n",
      ">1, 120/280, d1=0.672, d2=0.618 g=0.779\n",
      ">1, 121/280, d1=0.667, d2=0.621 g=0.778\n",
      ">1, 122/280, d1=0.675, d2=0.628 g=0.769\n",
      ">1, 123/280, d1=0.664, d2=0.630 g=0.766\n",
      ">1, 124/280, d1=0.660, d2=0.632 g=0.759\n",
      ">1, 125/280, d1=0.657, d2=0.644 g=0.752\n",
      ">1, 126/280, d1=0.645, d2=0.651 g=0.747\n",
      ">1, 127/280, d1=0.654, d2=0.656 g=0.736\n",
      ">1, 128/280, d1=0.642, d2=0.669 g=0.731\n",
      ">1, 129/280, d1=0.646, d2=0.678 g=0.718\n",
      ">1, 130/280, d1=0.636, d2=0.682 g=0.713\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = X_train\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def show_plot(examples, n):\n",
    "\t# plot images\n",
    "\tfor i in range(n * n):\n",
    "\t\t# define subplot\n",
    "\t\tplt.subplot(n, n, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tplt.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tplt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "\tplt.show()\n",
    "\n",
    "# load model\n",
    "model = load_model('generator.h5')\n",
    "# generate images\n",
    "latent_points = generate_latent_points(100, 100)\n",
    "# generate images\n",
    "X = model.predict(latent_points)\n",
    "# plot the result\n",
    "show_plot(X, 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ex.2-Q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
